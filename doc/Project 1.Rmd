---
title: "R Notebook"
output: html_notebook
---

```{r}
packages.used=c("rvest", "tibble", "qdap", 
                "sentimentr", "gplots", "dplyr",
                "tm", "syuzhet", "factoextra", 
                "beeswarm", "scales", "RColorBrewer",
                "RANN", "tm", "topicmodels","readtext")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")

source("../Desktop/plotstacked.R")
source("../Desktop/speechFuncs.R")
```

```{r}
textdata <- read.csv("philosophy_data.csv")
head(textdata)

```


#Cleaning the datasets
#school = feminism and finding their text related to female/women

#Term Document Analysis 
```{r}
library(tm)
feminism_text <- textdata[textdata$school=="feminism",'sentence_lowered']

g = grepl('female|sex|girl|womens|women|she',feminism_text)
feminism_text = feminism_text[g]
#length(feminism_text)

corpus <- iconv(feminism_text, to = 'utf-8-mac')
corpus <- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
#Cleaning datasets:
#Remove punctuations, lowercase, common words
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, tolower)
inspect(corpus[1:5])
corpus <- tm_map(corpus, removeNumbers)
inspect(corpus[1:5])
cleanset <- tm_map(corpus, removeWords, stopwords('english'))
cleanset <- tm_map(cleanset, removeWords, c('but','the', 'also'))
cleanset <- tm_map(cleanset, removeWords, 'I')
inspect(cleanset[1:5])
cleanset <- tm_map(cleanset, removeWords, c('the','but'))
list = c('this','thus','many','still','and','may','another','yet','these','that','â€¦','will','the','often','many','much','when','even')
cleanset <- tm_map(cleanset, removeWords, list)
inspect(cleanset[1:5])


cleanset <- tm_map(cleanset, gsub, pattern = 'women',replacement='woman')
cleanset <- tm_map(cleanset, gsub, pattern = 'womens',replacement='woman')
cleanset <- tm_map(cleanset, gsub, pattern = 'womans',replacement='woman')

cleanset <- tm_map(cleanset, gsub, pattern = 'feman', replacement = 'woman')
cleanset <- tm_map(cleanset, gsub, pattern = 'she',replacement='woman')
cleanset <- tm_map(cleanset, gsub, pattern = 'male',replacement='man')
cleanset <- tm_map(cleanset, gsub, pattern = 'men',replacement='man')
cleanset <- tm_map(cleanset, gsub, pattern = 'mens',replacement='man')
cleanset <- tm_map(cleanset, gsub, pattern = 'mans',replacement='man')
cleanset <- tm_map(cleanset, stemDocument)
cleanset <- tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])


```
```{r}
#Term document matrix
tdm <- TermDocumentMatrix(cleanset)
tdm <- as.matrix(tdm)
tdm[1:10, 1:20]


```

#Bar plot
```{r}
w <- sort(rowSums(tdm),decreasing = TRUE)
#Delete women and men
head(w,20)
w <- w[3:length(w)]
```

#school = feminism and their text keywords which related to female/women
```{r}
f_word_key <- subset(w, w>=300)
barplot(f_word_key, 
        las = 2,
        col = 'blue')
```

Similarly, we draw a wordcloud:

#Worldcloud for school-feminism
```{r}
library(wordcloud)
set.seed(2021)
f_freq_w <- subset(w, w>=100)

wordcloud(words = names(f_freq_w),
          freq = f_freq_w,
          max.words = 150,
          min.freq = 30,
          colors = brewer.pal(10, 'Dark2'),
         )
library(wordcloud2)
w_dataset <- data.frame(names(f_freq_w),f_freq_w)
colnames(w_dataset) <- c('word','freq')
wordcloud2(w_dataset,
           size = 0.8,
           shape = "circle")

?wordcloud2
```
From barchat and wordcloud, we can see that for feminism school, their keywords about women are mostly about love, sexual, like, world, mother, children and so on. We can take a closer look at the examples of text related with these keywords. 


#Converting corpus data into a dataframe
```{r}

dictCorpus <- cleanset
dataframe <- data.frame(text=sapply(dictCorpus, identity), 
    stringsAsFactors=F)

g_f_key_text <- grepl("feman|world|love|like|mother|child|freedom|fact", dataframe)
f_key_text <- dataframe[g_f_key_text]
f_key_text <- f_key_text[2:nrow(f_key_text), ]
tail(f_key_text,15)
```


Since I dropped stopwords from sentences, including object,predicate,preposition, such as I, you, could, out,on, of and so on, so sentences may not make much sense; however, if we focus on keywords that feminism use for describing female group, we can see a lot of words such as liberation, freedom, virtue, modesty, respect, moral, unite and so on.Therefore, we can conclude that feminism stand from women position and speak for women. They care about social justice, fairness, family position for a woman.
next, let's apply sentiment analysis on the same text from school feminism and we could more directly see authors' attitudes towards women.


#Sentiment Analysis
```{r}
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
```

#Sentiment bar chart
```{r}
#obtain sentiment score
fel_text <- iconv(cleanset, to = 'utf-8-mac')

s <- get_nrc_sentiment(fel_text)


barplot(colSums(s),
        las = 2,
        col = 'blue',
        ylab = 'Count')
```

From this bar chart, we could see that most sentences have sentiments negative and positive.
Then, we will see what are the topics that feminism school mainly talk about.

#Topic modeling 
```{r}
#install.packages('topicmodels')

dtm <- DocumentTermMatrix(cleanset)
#convert rownames to filenames#convert rownames to filenames
#rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
                      # corpus.list$Term, corpus.list$sent.id, sep="_")

rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document

dtm  <- dtm[rowTotals> 0, ]
corpus.list <- cleanset
#corpus.list=corpus.list[rowTotals>0, ]

#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE

#Number of topics
k <- 15
library(topicmodels)
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, 
                                                 seed = seed, best=best,
                                                 burnin = burnin, iter = iter, 
                                                 thin=thin))


ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
#top 6 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../Desktop",k,"TopicsToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../Desktop",k,"TopicProbabilities.csv"))


```

```{r}
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
  topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms

```

Based on the most popular terms and the most salient terms for each topic, we manually assign a hashtag to each topic. It is objective and might not be accurately correct. 

```{r}
topics.hash=c("temporal", "society_role", "perception", "spirit", "sexual", "thinking", "quest", "moral", "justice", "freedom", "family_role", "youth", "love", "expression", "ethic")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]

colnames(topicProbabilities)=topics.hash

corpus.list.df <- data.frame(text=sapply(corpus.list, identity), 
    stringsAsFactors=F)

corpus.list.df <- cbind(corpus.list.df, topicProbabilities)
head(corpus.list.df)

complete.corpus.list.df <- merge(corpus.list.df, feminism_text, by = "sentence_lowered")
head(textdata)

fem_txt <- textdata[textdata$school=="feminism", c("title","author","school","sentence_lowered","original_publication_date","corpus_edition_date","sentence_length")]
colnames(corpus.list.df)[1] <- "text"



```


## Clustering of topics

```{r, fig.width=3, fig.height=4}
library(gplots)
par(mar=c(1,1,1,1))
topic.summary=tbl_df(corpus.list.df)
topic.summary=as.data.frame(topic.summary)
rownames(topic.summary)=topic.summary[,1]

# [1] "Economy"         "America"         "Defense"         "Belief"         
# [5] "Election"        "Patriotism"      "Unity"           "Government"     
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"        
# [13] "Equality"        "Misc"            "Legislation"       

topic.plot=c(1, 13, 9, 11, 8, 3, 7)
print(topics.hash[topic.plot])

heatmap.2(as.matrix(topic.summary[,topic.plot+1]), 
          scale = "column", key=F, 
          col = bluered(100),
          cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
          trace = "none", density.info = "none")




```











#_______________________________________________
#What are the emotionally changed sentences?
```{r}



f.df=tbl_df(feminism_text)%>%
  select(value, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
head(f.df)



sentence.list=NULL
for(i in 1:nrow(all_text_f_date)){
  sentences=all_text_f_date$sentence_lowered[i]
  if(length(sentences)>0){
    emotions=get_nrc_sentiment(sentences)
    word.count=word_count(sentences)
    # colnames(emotions)=paste0("emo.", colnames(emotions))
    # in case the word counts are zeros?
    emotions=(1/(word.count+0.01))%*%as.matrix(emotions)
    sentence.list=rbind(sentence.list, 
                        cbind(f.df[i,-ncol(f.df)],
                              sentences=as.character(sentences), 
                              word.count,
                              emotions,
                              sent.id=1:length(sentences)
                              )
    )
  }
}



head(sentence.list)

```

### What are the emotionally charged sentences?
#For school feminism
```{r}

#move on
print("feminism ")
speech.df=tbl_df(sentence.list)%>%
  filter(school=="feminism",  word.count>=4)%>%
  select(sentence_lowered, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentence_lowered[apply(speech.df[,-1], 2, which.max)])

```

#For school Aristotle and Polato
```{r}

print("aristotle & plato ")
speech.df=tbl_df(sentence.list)%>%
  filter(school==c("plato","aristotle"),  word.count>=4)%>%
  select(sentence_lowered, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentence_lowered[apply(speech.df[,-1], 2, which.max)])

unique(sentence.list$school)

```

#?????To answer questions: are Aristotle and Polato hostile to women?

```{r}
emo.means=colMeans(select(sentence.list, anger:trust)>0.001)
col.use=c("darkgoldenrod1", "darkgoldenrod1", "darkgoldenrod1", "darkgoldenrod1",
            "red2", "chartreuse3", "blueviolet","dodgerblue3")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T, main="Sentences related to female")
```

```{r}
heatmap.2(cor(sentence.list%>%select(anger:trust)), 
          scale = "none", 
          col = bluered(100), , margin=c(6, 6), key=F,
          trace = "none", density.info = "none")



```
```{r}
presid.summary=tbl_df(sentence.list)%>%
  #group_by(paste0(type, File))%>%
  group_by(author)%>%
  summarise(
    anger=mean(anger),
    anticipation=mean(anticipation),
    disgust=mean(disgust),
    fear=mean(fear),
    joy=mean(joy),
    sadness=mean(sadness),
    surprise=mean(surprise),
    trust=mean(trust)
    #negative=mean(negative),
    #positive=mean(positive)
  )
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1], iter.max=200,
              4)
fviz_cluster(km.res, 
             stand=F, repel= TRUE,
             data = presid.summary[,-1], xlab="", xaxt="n",
             show.clust.cent=FALSE)



```

From above clustering charts, we apply KMeans on dataset containing sentiment scores. Data will cluster together if they have similar sentiment score and I split the data into 4 groups.So from above four clusters, taking the purple cluster as an example: it includes all authors from school feminism: Wollstonecraft, Beauvoir and Davis, so 


```{r}
unique(textdata[textdata$school=="feminism",'author'])


```

#Classic Philosophy-Aristotle & Polato
#select AP group text related to female/women
```{r}
#Comparing feminism to Aristotle, Palato
AP_text <- textdata[textdata$school==c("aristotle","plato"),'sentence_lowered']
AP <- grepl("female|girl|womens|women|she|feman", AP_text)
AP_text <- AP_text[AP]
length(AP_text)
#head(AP_text)
#cleaning the dataset
corpus_AP <- iconv(AP_text, to = 'utf-8-mac')
corpus_AP <- Corpus(VectorSource(corpus_AP))

corpus_AP <- tm_map(corpus_AP, tolower)
corpus_AP <- tm_map(corpus_AP, removePunctuation)
corpus_AP <- tm_map(corpus_AP, removeNumbers)
corpus_AP <- tm_map(corpus_AP, removeWords, stopwords('english'))
corpus_AP <- tm_map(corpus_AP, removeWords, 'I')
inspect(corpus_AP[1:5])
corpus_AP <- tm_map(corpus_AP, removeWords, 'the')
corpus_AP <- tm_map(corpus_AP, removeWords, 'but')

corpus_AP <- tm_map(corpus_AP, removeWords, "one")
corpus_AP <- tm_map(corpus_AP, removeWords, "also")
corpus_AP <- tm_map(corpus_AP, removeWords, "will")
corpus_AP <- tm_map(corpus_AP, removeWords, "just")

corpus_AP <- tm_map(corpus_AP, removeWords, c('women','female','womens','woman','she','womans','femans','girls'))
inspect(corpus_AP[1:5])
corpus_AP <- tm_map(corpus_AP, gsub, pattern = 'men',replacement = 'man')
corpus_AP <- tm_map(corpus_AP, gsub, pattern = 'male', replacement = 'man')
corpus_AP <- tm_map(corpus_AP, gsub, pattern = 'boy', replacement = 'man')
corpus_AP <- tm_map(corpus_AP, gsub, pattern = 'mans', replacement = 'man')

clean_AP <- tm_map(corpus_AP, stripWhitespace)
inspect(clean_AP[1:5])
```

```{r}

tmd_AP <- TermDocumentMatrix(clean_AP)
tmd_AP <- as.matrix(tmd_AP)
tmd_AP[1:10,1:20]

#Bar plot
w_AP <- sort(rowSums(tmd_AP), decreasing = TRUE)

head(w_AP,100)

AP_freq_key <- subset(w_AP, w_AP>20)
barplot(AP_freq_key,
        las = 2,
        ylab = 'count',
        col = 'blue')

```

#Sentiment Analysis
```{r}
corpus_AP <- tm_map(corpus_AP, removeWords, "man")
clean_AP <- tm_map(corpus_AP, stripWhitespace)
tmd_AP <- TermDocumentMatrix(clean_AP)
tmd_AP <- as.matrix(tmd_AP)
w_AP <- sort(rowSums(tmd_AP), decreasing = TRUE)
set.seed(2021)
AP_freq_w <- subset(w_AP, w_AP>=10)

wordcloud(words = names(AP_freq_w),
          freq = AP_freq_w,
          colors = brewer.pal(10, 'Dark2'),
          scale = c(8,0.3))
```

```{r}
AP_text <- iconv(clean_AP, to = 'utf-8-mac')
AP_text <- get_nrc_sentiment(AP_text)

barplot(colSums(AP_text),
        las = 2,
        col = 'blue',
        ylab = 'Count')


```

#May delete later
```{r}
unique(textdata[textdata$school==c("plato","aristotle"),]$title)
unique(textdata[textdata$school=="feminism",]$title)
unique(textdata[textdata$author=='Kant',]$title)
unique(textdata$author)
unique(textdata[textdata$school==c("plato","aristotle"),]$title)
```

#text related to female, number of text over time (each bar divided by school)

```{r}
library(dplyr)
library(tidyr)

#Problem: only select whole datasets
#To solve: split the dataset by school, then count how many sentences related to women


#For loop: adding texts related to female
schools <- unique(textdata$school)
all_text_f <-  NULL
for (i in schools){
  subtext <- textdata[textdata$school==i, c("sentence_lowered","original_publication_date","sentence_length")]
  subtext_g <- grep("female|women|woman|womens|girl", subtext$sentence_lowered, value = TRUE)
  all_text_f <- append(all_text_f, subtext_g) 
}
length(all_text_f)
head(all_text_f)
all_text_f <- data.frame(all_text_f)
colnames(all_text_f) <- "sentence_lowered"
all_text_f_date <- merge(all_text_f, textdata, by="sentence_lowered")
head(all_text_f_date)

```

```{r}
unique(textdata$school)
unique(all_text_f_date$school)
```

```{r}
library(forcats)
library(ggplot2)
school_sentence <- all_text_f_date%>%
  group_by(school)%>%
  summarise(num_sentence = n())%>%
  arrange(desc(num_sentence))
#(school_sentence)

#Total num of sentences over all schools
school_sentence%>%
  ggplot(aes(x = school, y = num_sentence))+
  geom_bar(stat = "identity", fill="#f68060", alpha=.6, width=.4)+
  coord_flip()+
  xlab("school")+
  ylab("number of sentences")+
  theme_bw()+
  labs(title = "Number of Sentences related to women over different schools")

```


```{r}
#install.packages("beeswarm")

library(beeswarm)
library(RColorBrewer)
par(las = 1)
beeswarm(sentence_length~school, data = all_text_f_date, horizontal=TRUE,
         pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), 
         cex=0.55, cex.axis=0.8, cex.lab=0.8,
         spacing=1.2/nlevels(factor(all_text_f_date$school)),
         las=2, xlab="Number of Words in a Sentence.", ylab="",
         main="The distribution of sentence lengths related to female over different school")

```


```{r}
date_sentence <- all_text_f_date%>%
  group_by(original_publication_date)%>%
  summarise(count = n())%>%
  arrange(original_publication_date)
ggplot(aes(x = original_publication_date, y = count), data = date_sentence)+

library(ggplot2)
library(dplyr)

date_sentence$original_publication_date <- as.Date(date_sentence$original_publication_date)
year <- as.character(date_sentence$original_publication_date)

date_sentence %>%
  ggplot( aes(x=year, y=count)) +
    geom_area(fill="#69b3a2", alpha=0.5) +
  geom_bar(stat = "identity", fill="#f68060", alpha=.6, width=.4)+
    #geom_line(color="#69b3a2") +
    ylab("Number of sentences") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  labs(title = "Number of sentences related to Women over years")
```